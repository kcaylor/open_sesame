{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core Module\n",
    "\n",
    "> Base types, enumerations, and error classes for the openness classifier.\n",
    "\n",
    "This module provides the foundational data structures used throughout the library:\n",
    "\n",
    "- **OpennessCategory**: 4-category ordinal taxonomy for classification\n",
    "- **ClassificationType**: Whether classifying data or code statements\n",
    "- **Classification**: Result of a classification with metadata\n",
    "- **LLMProvider**: Abstraction for multi-provider LLM support\n",
    "- **Error classes**: Custom exceptions for error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "from typing import Optional, Dict, Any, List\n",
    "from pathlib import Path\n",
    "import json\n",
    "import hashlib\n",
    "import time\n",
    "import logging\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enumerations\n",
    "\n",
    "### OpennessCategory\n",
    "\n",
    "The 4-category ordinal taxonomy for classifying data/code openness, based on the rubric from articles_reviewed.csv:\n",
    "\n",
    "| Category | Description | Examples |\n",
    "|----------|-------------|----------|\n",
    "| open | Fully accessible, no restrictions | Zenodo, Figshare, public GitHub |\n",
    "| mostly_open | Largely accessible with minor restrictions | Registration required, institutional access |\n",
    "| mostly_closed | Largely restricted with limited access | Data use agreements, partial availability |\n",
    "| closed | Not accessible | \"Upon request\", confidential, proprietary |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OpennessCategory(str, Enum):\n",
    "    \"\"\"4-category ordinal taxonomy for data/code openness classification.\n",
    "    \n",
    "    Categories are ordered from most open to least open:\n",
    "    open > mostly_open > mostly_closed > closed\n",
    "    \n",
    "    Classification Rules (per articles_reviewed.csv rubric):\n",
    "    - OPEN: Public repository with no barriers (Zenodo, Figshare, GitHub public)\n",
    "    - MOSTLY_OPEN: Public repository with registration, institutional access\n",
    "    - MOSTLY_CLOSED: Data use agreements, partial availability, some restrictions\n",
    "    - CLOSED: \"Available upon request\", confidential, not accessible\n",
    "    \"\"\"\n",
    "    OPEN = \"open\"\n",
    "    MOSTLY_OPEN = \"mostly_open\"\n",
    "    MOSTLY_CLOSED = \"mostly_closed\"\n",
    "    CLOSED = \"closed\"\n",
    "    \n",
    "    @classmethod\n",
    "    def from_string(cls, value: str) -> 'OpennessCategory':\n",
    "        \"\"\"Parse category from string, handling various formats.\n",
    "        \n",
    "        Handles mappings from articles_reviewed.csv:\n",
    "        - 'Closed', 'closed' -> CLOSED\n",
    "        - 'Partially Closed', 'mostly closed', 'mostly_closed' -> MOSTLY_CLOSED\n",
    "        - 'Partially Open', 'mostly open', 'mostly_open' -> MOSTLY_OPEN  \n",
    "        - 'Open', 'open' -> OPEN\n",
    "        \"\"\"\n",
    "        normalized = value.lower().strip().replace(' ', '_').replace('-', '_')\n",
    "        \n",
    "        # Handle articles_reviewed.csv format\n",
    "        mapping = {\n",
    "            'closed': cls.CLOSED,\n",
    "            'partially_closed': cls.MOSTLY_CLOSED,\n",
    "            'mostly_closed': cls.MOSTLY_CLOSED,\n",
    "            'partially_open': cls.MOSTLY_OPEN,\n",
    "            'mostly_open': cls.MOSTLY_OPEN,\n",
    "            'open': cls.OPEN,\n",
    "        }\n",
    "        \n",
    "        if normalized in mapping:\n",
    "            return mapping[normalized]\n",
    "        \n",
    "        raise ValueError(f\"Unknown openness category: {value}\")\n",
    "    \n",
    "    def __lt__(self, other: 'OpennessCategory') -> bool:\n",
    "        \"\"\"Compare categories by openness level (closed < mostly_closed < mostly_open < open).\"\"\"\n",
    "        order = [self.CLOSED, self.MOSTLY_CLOSED, self.MOSTLY_OPEN, self.OPEN]\n",
    "        return order.index(self) < order.index(other)\n",
    "    \n",
    "    def __le__(self, other: 'OpennessCategory') -> bool:\n",
    "        return self == other or self < other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test OpennessCategory\n",
    "assert OpennessCategory.from_string(\"Closed\") == OpennessCategory.CLOSED\n",
    "assert OpennessCategory.from_string(\"Partially Closed\") == OpennessCategory.MOSTLY_CLOSED\n",
    "assert OpennessCategory.from_string(\"open\") == OpennessCategory.OPEN\n",
    "assert OpennessCategory.CLOSED < OpennessCategory.OPEN\n",
    "print(\"OpennessCategory tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ClassificationType(str, Enum):\n",
    "    \"\"\"Type of availability statement being classified.\"\"\"\n",
    "    DATA = \"data\"\n",
    "    CODE = \"code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LLMProviderType(str, Enum):\n",
    "    \"\"\"Supported LLM provider types.\"\"\"\n",
    "    CLAUDE = \"claude\"\n",
    "    OPENAI = \"openai\"\n",
    "    OLLAMA = \"ollama\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BatchStatus(str, Enum):\n",
    "    \"\"\"Status of a batch processing job.\"\"\"\n",
    "    PENDING = \"pending\"\n",
    "    RUNNING = \"running\"\n",
    "    COMPLETED = \"completed\"\n",
    "    FAILED = \"failed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Classes\n",
    "\n",
    "Custom exceptions for better error handling and debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ClassificationError(Exception):\n",
    "    \"\"\"Base exception for classification errors.\"\"\"\n",
    "    pass\n",
    "\n",
    "class LLMError(ClassificationError):\n",
    "    \"\"\"Error from LLM provider (API failure, rate limit, etc.).\"\"\"\n",
    "    def __init__(self, message: str, provider: str = None, retryable: bool = False):\n",
    "        super().__init__(message)\n",
    "        self.provider = provider\n",
    "        self.retryable = retryable\n",
    "\n",
    "class ConfigurationError(ClassificationError):\n",
    "    \"\"\"Error in configuration (missing API key, invalid settings).\"\"\"\n",
    "    pass\n",
    "\n",
    "class DataError(ClassificationError):\n",
    "    \"\"\"Error in data loading or processing.\"\"\"\n",
    "    pass\n",
    "\n",
    "class ValidationError(ClassificationError):\n",
    "    \"\"\"Error in validation (invalid category, missing ground truth).\"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Classes\n",
    "\n",
    "### LLMConfiguration\n",
    "\n",
    "Tracks language model configuration for reproducibility (FAIR principles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class LLMConfiguration:\n",
    "    \"\"\"Configuration for LLM provider, tracked for reproducibility.\n",
    "    \n",
    "    Attributes:\n",
    "        provider: LLM provider type (claude, openai, ollama)\n",
    "        model_name: Model identifier (e.g., 'claude-3-5-sonnet-20241022')\n",
    "        temperature: Sampling temperature (default: 0.1 for consistency)\n",
    "        max_tokens: Maximum response tokens (default: 500)\n",
    "        top_p: Nucleus sampling parameter (default: 0.95)\n",
    "        api_endpoint: Optional custom API endpoint (for Ollama)\n",
    "        api_key_hash: SHA-256 hash of API key for audit trail (never store key itself)\n",
    "    \"\"\"\n",
    "    provider: LLMProviderType\n",
    "    model_name: str\n",
    "    temperature: float = 0.1\n",
    "    max_tokens: int = 500\n",
    "    top_p: float = 0.95\n",
    "    api_endpoint: Optional[str] = None\n",
    "    api_key_hash: Optional[str] = None\n",
    "    configuration_timestamp: datetime = field(default_factory=datetime.utcnow)\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for JSON serialization.\"\"\"\n",
    "        return {\n",
    "            'provider': self.provider.value,\n",
    "            'model_name': self.model_name,\n",
    "            'temperature': self.temperature,\n",
    "            'max_tokens': self.max_tokens,\n",
    "            'top_p': self.top_p,\n",
    "            'api_endpoint': self.api_endpoint,\n",
    "            'api_key_hash': self.api_key_hash,\n",
    "            'configuration_timestamp': self.configuration_timestamp.isoformat(),\n",
    "        }\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dict(cls, data: Dict[str, Any]) -> 'LLMConfiguration':\n",
    "        \"\"\"Create from dictionary.\"\"\"\n",
    "        return cls(\n",
    "            provider=LLMProviderType(data['provider']),\n",
    "            model_name=data['model_name'],\n",
    "            temperature=data.get('temperature', 0.1),\n",
    "            max_tokens=data.get('max_tokens', 500),\n",
    "            top_p=data.get('top_p', 0.95),\n",
    "            api_endpoint=data.get('api_endpoint'),\n",
    "            api_key_hash=data.get('api_key_hash'),\n",
    "            configuration_timestamp=datetime.fromisoformat(data['configuration_timestamp'])\n",
    "                if 'configuration_timestamp' in data else datetime.utcnow(),\n",
    "        )\n",
    "    \n",
    "    def to_json(self) -> str:\n",
    "        \"\"\"Serialize to JSON string.\"\"\"\n",
    "        return json.dumps(self.to_dict(), indent=2)\n",
    "    \n",
    "    @staticmethod\n",
    "    def hash_api_key(api_key: str) -> str:\n",
    "        \"\"\"Create SHA-256 hash of API key for audit trail.\"\"\"\n",
    "        return hashlib.sha256(api_key.encode()).hexdigest()[:16]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification\n",
    "\n",
    "Result of classifying a single statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class Classification:\n",
    "    \"\"\"Result of classifying a data or code availability statement.\n",
    "    \n",
    "    Attributes:\n",
    "        category: The classified openness category\n",
    "        statement_type: Whether this is a data or code classification\n",
    "        confidence_score: Model confidence (0-1), higher is more confident\n",
    "        reasoning: Optional chain-of-thought reasoning from LLM\n",
    "        timestamp: When classification was made (UTC)\n",
    "        model_config: LLM configuration used for reproducibility\n",
    "        few_shot_example_ids: IDs of training examples used in prompt\n",
    "    \"\"\"\n",
    "    category: OpennessCategory\n",
    "    statement_type: ClassificationType\n",
    "    confidence_score: float = 0.8\n",
    "    reasoning: Optional[str] = None\n",
    "    timestamp: datetime = field(default_factory=datetime.utcnow)\n",
    "    model_config: Optional[LLMConfiguration] = None\n",
    "    few_shot_example_ids: List[str] = field(default_factory=list)\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Validate confidence score is in range [0, 1].\"\"\"\n",
    "        if not 0 <= self.confidence_score <= 1:\n",
    "            raise ValueError(f\"confidence_score must be between 0 and 1, got {self.confidence_score}\")\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for JSON serialization.\"\"\"\n",
    "        return {\n",
    "            'category': self.category.value,\n",
    "            'statement_type': self.statement_type.value,\n",
    "            'confidence_score': self.confidence_score,\n",
    "            'reasoning': self.reasoning,\n",
    "            'timestamp': self.timestamp.isoformat(),\n",
    "            'model_config': self.model_config.to_dict() if self.model_config else None,\n",
    "            'few_shot_example_ids': self.few_shot_example_ids,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Provider Abstraction\n",
    "\n",
    "Using LiteLLM for unified interface across Claude, OpenAI, and Ollama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LLMProvider:\n",
    "    \"\"\"Unified LLM provider interface using LiteLLM.\n",
    "    \n",
    "    Supports Claude, OpenAI, and Ollama with consistent interface.\n",
    "    Includes retry logic with exponential backoff for transient errors.\n",
    "    \n",
    "    Example:\n",
    "        >>> config = LLMConfiguration(\n",
    "        ...     provider=LLMProviderType.CLAUDE,\n",
    "        ...     model_name='claude-3-5-sonnet-20241022'\n",
    "        ... )\n",
    "        >>> provider = LLMProvider(config)\n",
    "        >>> response = provider.complete(\"Classify this statement...\")\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: LLMConfiguration):\n",
    "        self.config = config\n",
    "        self._setup_provider()\n",
    "    \n",
    "    def _setup_provider(self):\n",
    "        \"\"\"Configure the LLM provider based on config.\"\"\"\n",
    "        # LiteLLM uses model prefixes to route to providers\n",
    "        # claude/ for Anthropic, gpt- for OpenAI, ollama/ for Ollama\n",
    "        if self.config.provider == LLMProviderType.CLAUDE:\n",
    "            self.model_id = self.config.model_name\n",
    "            if not self.model_id.startswith('claude'):\n",
    "                self.model_id = f\"claude/{self.model_id}\"\n",
    "        elif self.config.provider == LLMProviderType.OPENAI:\n",
    "            self.model_id = self.config.model_name\n",
    "        elif self.config.provider == LLMProviderType.OLLAMA:\n",
    "            self.model_id = f\"ollama/{self.config.model_name}\"\n",
    "            if self.config.api_endpoint:\n",
    "                os.environ['OLLAMA_API_BASE'] = self.config.api_endpoint\n",
    "        else:\n",
    "            raise ConfigurationError(f\"Unknown provider: {self.config.provider}\")\n",
    "    \n",
    "    def complete(\n",
    "        self, \n",
    "        prompt: str,\n",
    "        max_retries: int = 3,\n",
    "        retry_delay: float = 1.0\n",
    "    ) -> str:\n",
    "        \"\"\"Generate completion for the given prompt.\n",
    "        \n",
    "        Args:\n",
    "            prompt: The prompt to complete\n",
    "            max_retries: Maximum number of retry attempts\n",
    "            retry_delay: Initial delay between retries (doubles each retry)\n",
    "            \n",
    "        Returns:\n",
    "            The model's response text\n",
    "            \n",
    "        Raises:\n",
    "            LLMError: If all retries fail\n",
    "        \"\"\"\n",
    "        import litellm\n",
    "        \n",
    "        last_error = None\n",
    "        delay = retry_delay\n",
    "        \n",
    "        for attempt in range(max_retries + 1):\n",
    "            try:\n",
    "                response = litellm.completion(\n",
    "                    model=self.model_id,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    temperature=self.config.temperature,\n",
    "                    max_tokens=self.config.max_tokens,\n",
    "                    top_p=self.config.top_p,\n",
    "                )\n",
    "                return response.choices[0].message.content\n",
    "            except Exception as e:\n",
    "                last_error = e\n",
    "                error_str = str(e).lower()\n",
    "                \n",
    "                # Check if error is retryable\n",
    "                retryable = any(x in error_str for x in [\n",
    "                    'rate limit', 'timeout', 'overloaded', \n",
    "                    'service unavailable', '529', '503', '504'\n",
    "                ])\n",
    "                \n",
    "                if retryable and attempt < max_retries:\n",
    "                    logging.warning(\n",
    "                        f\"LLM request failed (attempt {attempt + 1}/{max_retries + 1}): {e}. \"\n",
    "                        f\"Retrying in {delay:.1f}s...\"\n",
    "                    )\n",
    "                    time.sleep(delay)\n",
    "                    delay *= 2  # Exponential backoff\n",
    "                else:\n",
    "                    break\n",
    "        \n",
    "        raise LLMError(\n",
    "            f\"LLM request failed after {max_retries + 1} attempts: {last_error}\",\n",
    "            provider=self.config.provider.value,\n",
    "            retryable=False\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Logging\n",
    "\n",
    "JSON Lines format logging for reproducibility tracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ClassificationLogger:\n",
    "    \"\"\"Logger for classification decisions in JSON Lines format.\n",
    "    \n",
    "    Logs all classification decisions with full metadata for:\n",
    "    - Reproducibility (FAIR principles)\n",
    "    - Audit trail\n",
    "    - Debugging and analysis\n",
    "    \n",
    "    Example:\n",
    "        >>> logger = ClassificationLogger('logs/classifications.jsonl')\n",
    "        >>> logger.log_classification(\n",
    "        ...     publication_id='doi:10.1234/example',\n",
    "        ...     classification=classification_result,\n",
    "        ...     statement_text='Data available at Zenodo...'\n",
    "        ... )\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, log_path: str | Path):\n",
    "        self.log_path = Path(log_path)\n",
    "        self.log_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    def log_classification(\n",
    "        self,\n",
    "        publication_id: str,\n",
    "        classification: Classification,\n",
    "        statement_text: str,\n",
    "        extra: Optional[Dict[str, Any]] = None\n",
    "    ):\n",
    "        \"\"\"Log a classification decision.\n",
    "        \n",
    "        Args:\n",
    "            publication_id: Unique identifier for the publication\n",
    "            classification: The classification result\n",
    "            statement_text: The original statement text\n",
    "            extra: Optional additional metadata\n",
    "        \"\"\"\n",
    "        log_entry = {\n",
    "            'timestamp': datetime.utcnow().isoformat(),\n",
    "            'publication_id': publication_id,\n",
    "            'statement_type': classification.statement_type.value,\n",
    "            'statement_text': statement_text[:500],  # Truncate for log size\n",
    "            'classification': classification.to_dict(),\n",
    "        }\n",
    "        \n",
    "        if extra:\n",
    "            log_entry['extra'] = extra\n",
    "        \n",
    "        with open(self.log_path, 'a') as f:\n",
    "            f.write(json.dumps(log_entry) + '\\n')\n",
    "    \n",
    "    def log_error(\n",
    "        self,\n",
    "        publication_id: str,\n",
    "        error: Exception,\n",
    "        context: Optional[Dict[str, Any]] = None\n",
    "    ):\n",
    "        \"\"\"Log a classification error.\"\"\"\n",
    "        log_entry = {\n",
    "            'timestamp': datetime.utcnow().isoformat(),\n",
    "            'publication_id': publication_id,\n",
    "            'error': True,\n",
    "            'error_type': type(error).__name__,\n",
    "            'error_message': str(error),\n",
    "        }\n",
    "        \n",
    "        if context:\n",
    "            log_entry['context'] = context\n",
    "        \n",
    "        with open(self.log_path, 'a') as f:\n",
    "            f.write(json.dumps(log_entry) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Classification dataclass\n",
    "test_config = LLMConfiguration(\n",
    "    provider=LLMProviderType.CLAUDE,\n",
    "    model_name='claude-3-5-sonnet-20241022'\n",
    ")\n",
    "\n",
    "test_classification = Classification(\n",
    "    category=OpennessCategory.OPEN,\n",
    "    statement_type=ClassificationType.DATA,\n",
    "    confidence_score=0.92,\n",
    "    reasoning=\"Data is available on Zenodo with no restrictions.\",\n",
    "    model_config=test_config\n",
    ")\n",
    "\n",
    "print(f\"Classification: {test_classification.category.value}\")\n",
    "print(f\"Confidence: {test_classification.confidence_score}\")\n",
    "print(\"Classification tests passed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "# nbdev requires this cell to export\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
