{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Batch Processing\n",
    "\n",
    "This tutorial demonstrates how to classify multiple publications from a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openness_classifier.batch import classify_csv, BatchJob\n",
    "from openness_classifier.config import load_config\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Basic Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process a CSV file\n",
    "input_path = Path('../../resources/abpoll-open-b71bd12/data/processed/articles_reviewed.csv')\n",
    "\n",
    "if input_path.exists():\n",
    "    # Load a small subset for demo\n",
    "    df = pd.read_csv(input_path).head(10)\n",
    "    subset_path = Path('../../data/demo_subset.csv')\n",
    "    df.to_csv(subset_path, index=False)\n",
    "    \n",
    "    # Process with progress callback\n",
    "    def progress(processed, total):\n",
    "        print(f\"\\rProcessing: {processed}/{total} ({100*processed/total:.0f}%)\", end=\"\")\n",
    "    \n",
    "    job = classify_csv(\n",
    "        input_path=subset_path,\n",
    "        output_path=Path('../../data/demo_classified.csv'),\n",
    "        progress_callback=progress\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n\\n{job.summary()}\")\n",
    "else:\n",
    "    print(f\"Input file not found: {input_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Review Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display results\n",
    "result_path = Path('../../data/demo_classified.csv')\n",
    "if result_path.exists():\n",
    "    results = pd.read_csv(result_path)\n",
    "    print(\"Classification Results:\")\n",
    "    print(results[['doi', 'data_classification', 'data_confidence', \n",
    "                   'code_classification', 'code_confidence']].to_string())\n",
    "    \n",
    "    print(\"\\n\\nData Classification Distribution:\")\n",
    "    print(results['data_classification'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Error Handling Options\n",
    "\n",
    "The `error_handling` parameter controls behavior on failures:\n",
    "- `'skip'`: Skip failed rows, continue processing\n",
    "- `'fail'`: Stop on first error\n",
    "- `'log'`: Log error and continue (default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check job error log\n",
    "if 'job' in dir():\n",
    "    if job.error_log:\n",
    "        print(\"Errors encountered:\")\n",
    "        for pub_id, error in job.error_log:\n",
    "            print(f\"  {pub_id}: {error}\")\n",
    "    else:\n",
    "        print(\"No errors encountered!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Key functions:\n",
    "- `classify_csv()`: Process a CSV file with multiple publications\n",
    "- `BatchJob`: Track progress, statistics, and errors\n",
    "- `progress_callback`: Monitor progress in real-time\n",
    "\n",
    "Output columns added:\n",
    "- `data_classification`: Openness category for data\n",
    "- `data_confidence`: Confidence score (0-1)\n",
    "- `code_classification`: Openness category for code\n",
    "- `code_confidence`: Confidence score (0-1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
