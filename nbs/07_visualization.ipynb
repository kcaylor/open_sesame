{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization Module\n",
    "\n",
    "> Plotting functions for validation results and confusion matrices.\n",
    "\n",
    "This module provides:\n",
    "- `plot_confusion_matrix()`: Heatmap visualization of confusion matrices\n",
    "- `plot_metrics_comparison()`: Bar charts comparing model versions\n",
    "- `plot_class_distribution()`: Training data distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from typing import Optional, List, Dict, Any\n",
    "\n",
    "from openness_classifier.validation import ValidationResult, ClassificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# Default style settings for publication-quality figures\n",
    "FIGURE_STYLE = {\n",
    "    'figure.figsize': (8, 6),\n",
    "    'font.size': 12,\n",
    "    'axes.titlesize': 14,\n",
    "    'axes.labelsize': 12,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "}\n",
    "\n",
    "CATEGORY_ORDER = ['open', 'mostly_open', 'mostly_closed', 'closed']\n",
    "CATEGORY_LABELS = ['Open', 'Mostly\\nOpen', 'Mostly\\nClosed', 'Closed']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_confusion_matrix(\n",
    "    confusion_matrix: np.ndarray,\n",
    "    title: str = \"Confusion Matrix\",\n",
    "    labels: Optional[List[str]] = None,\n",
    "    normalize: bool = False,\n",
    "    cmap: str = \"Blues\",\n",
    "    figsize: tuple = (8, 6),\n",
    "    save_path: Optional[str | Path] = None,\n",
    ") -> plt.Figure:\n",
    "    \"\"\"Plot confusion matrix as heatmap.\n",
    "    \n",
    "    Args:\n",
    "        confusion_matrix: NxN confusion matrix array\n",
    "        title: Plot title\n",
    "        labels: Axis labels (default: openness categories)\n",
    "        normalize: If True, normalize by row (true label)\n",
    "        cmap: Colormap name\n",
    "        figsize: Figure size\n",
    "        save_path: Optional path to save figure\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib Figure object\n",
    "    \"\"\"\n",
    "    if labels is None:\n",
    "        labels = CATEGORY_LABELS\n",
    "    \n",
    "    # Normalize if requested\n",
    "    if normalize:\n",
    "        cm = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1, keepdims=True)\n",
    "        cm = np.nan_to_num(cm)  # Handle division by zero\n",
    "        fmt = '.2f'\n",
    "    else:\n",
    "        cm = confusion_matrix\n",
    "        fmt = 'd'\n",
    "    \n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Plot heatmap\n",
    "    sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=fmt,\n",
    "        cmap=cmap,\n",
    "        xticklabels=labels,\n",
    "        yticklabels=labels,\n",
    "        ax=ax,\n",
    "        cbar_kws={'label': 'Proportion' if normalize else 'Count'},\n",
    "    )\n",
    "    \n",
    "    ax.set_xlabel('Predicted Label')\n",
    "    ax.set_ylabel('True Label')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_validation_results(\n",
    "    result: ValidationResult,\n",
    "    save_dir: Optional[str | Path] = None,\n",
    ") -> Dict[str, plt.Figure]:\n",
    "    \"\"\"Plot all visualizations for a validation result.\n",
    "    \n",
    "    Creates confusion matrices for data and code classifications.\n",
    "    \n",
    "    Args:\n",
    "        result: ValidationResult to visualize\n",
    "        save_dir: Optional directory to save figures\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary of {name: figure} for all created plots\n",
    "    \"\"\"\n",
    "    figures = {}\n",
    "    \n",
    "    if save_dir:\n",
    "        save_dir = Path(save_dir)\n",
    "        save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Data confusion matrix\n",
    "    if 'data' in result.confusion_matrices:\n",
    "        fig = plot_confusion_matrix(\n",
    "            result.confusion_matrices['data'],\n",
    "            title='Data Availability Classification',\n",
    "            save_path=save_dir / 'confusion_matrix_data.png' if save_dir else None,\n",
    "        )\n",
    "        figures['data_confusion'] = fig\n",
    "        \n",
    "        # Normalized version\n",
    "        fig_norm = plot_confusion_matrix(\n",
    "            result.confusion_matrices['data'],\n",
    "            title='Data Availability Classification (Normalized)',\n",
    "            normalize=True,\n",
    "            save_path=save_dir / 'confusion_matrix_data_normalized.png' if save_dir else None,\n",
    "        )\n",
    "        figures['data_confusion_normalized'] = fig_norm\n",
    "    \n",
    "    # Code confusion matrix\n",
    "    if 'code' in result.confusion_matrices:\n",
    "        fig = plot_confusion_matrix(\n",
    "            result.confusion_matrices['code'],\n",
    "            title='Code Availability Classification',\n",
    "            save_path=save_dir / 'confusion_matrix_code.png' if save_dir else None,\n",
    "        )\n",
    "        figures['code_confusion'] = fig\n",
    "    \n",
    "    return figures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_metrics_comparison(\n",
    "    metrics_list: List[ClassificationMetrics],\n",
    "    labels: List[str],\n",
    "    title: str = \"Model Comparison\",\n",
    "    figsize: tuple = (10, 6),\n",
    "    save_path: Optional[str | Path] = None,\n",
    ") -> plt.Figure:\n",
    "    \"\"\"Plot bar chart comparing metrics across models/runs.\n",
    "    \n",
    "    Args:\n",
    "        metrics_list: List of ClassificationMetrics to compare\n",
    "        labels: Labels for each metrics set\n",
    "        title: Plot title\n",
    "        figsize: Figure size\n",
    "        save_path: Optional path to save figure\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib Figure object\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    x = np.arange(len(labels))\n",
    "    width = 0.2\n",
    "    \n",
    "    # Extract metrics\n",
    "    accuracies = [m.accuracy for m in metrics_list]\n",
    "    kappas = [m.cohens_kappa for m in metrics_list]\n",
    "    macro_f1s = [m.macro_f1 for m in metrics_list]\n",
    "    \n",
    "    # Plot bars\n",
    "    ax.bar(x - width, accuracies, width, label='Accuracy', color='#2ecc71')\n",
    "    ax.bar(x, kappas, width, label=\"Cohen's Kappa\", color='#3498db')\n",
    "    ax.bar(x + width, macro_f1s, width, label='Macro F1', color='#9b59b6')\n",
    "    \n",
    "    ax.set_xlabel('Model')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.legend()\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.axhline(y=0.8, color='gray', linestyle='--', alpha=0.5, label='Target (80%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_class_distribution(\n",
    "    distribution: Dict[str, int],\n",
    "    title: str = \"Training Data Distribution\",\n",
    "    figsize: tuple = (8, 5),\n",
    "    save_path: Optional[str | Path] = None,\n",
    ") -> plt.Figure:\n",
    "    \"\"\"Plot bar chart of class distribution.\n",
    "    \n",
    "    Args:\n",
    "        distribution: Dict mapping category names to counts\n",
    "        title: Plot title\n",
    "        figsize: Figure size\n",
    "        save_path: Optional path to save figure\n",
    "        \n",
    "    Returns:\n",
    "        matplotlib Figure object\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    \n",
    "    # Order categories\n",
    "    categories = [c for c in CATEGORY_ORDER if c in distribution]\n",
    "    counts = [distribution[c] for c in categories]\n",
    "    labels = [CATEGORY_LABELS[CATEGORY_ORDER.index(c)] for c in categories]\n",
    "    \n",
    "    colors = ['#27ae60', '#2ecc71', '#e74c3c', '#c0392b']\n",
    "    \n",
    "    bars = ax.bar(labels, counts, color=colors[:len(categories)])\n",
    "    \n",
    "    # Add count labels on bars\n",
    "    for bar, count in zip(bars, counts):\n",
    "        ax.text(\n",
    "            bar.get_x() + bar.get_width()/2,\n",
    "            bar.get_height() + 0.5,\n",
    "            str(count),\n",
    "            ha='center',\n",
    "            va='bottom',\n",
    "            fontsize=10,\n",
    "        )\n",
    "    \n",
    "    ax.set_xlabel('Openness Category')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        fig.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test confusion matrix plotting\n",
    "cm = np.array([\n",
    "    [10, 2, 0, 0],\n",
    "    [1, 8, 1, 0],\n",
    "    [0, 2, 6, 2],\n",
    "    [0, 0, 1, 9],\n",
    "])\n",
    "\n",
    "fig = plot_confusion_matrix(cm, title=\"Test Confusion Matrix\")\n",
    "plt.show()\n",
    "print(\"Visualization module ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
