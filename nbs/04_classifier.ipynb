{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier Module\n",
    "\n",
    "> Core classification functions for data and code availability statements.\n",
    "\n",
    "This module provides:\n",
    "- `classify_statement()`: Classify a single availability statement\n",
    "- `classify_publication()`: Classify both data and code for a publication\n",
    "\n",
    "The classifier uses few-shot learning with semantically similar examples selected via kNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from typing import Optional, List, Tuple\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "from openness_classifier.core import (\n",
    "    OpennessCategory,\n",
    "    ClassificationType,\n",
    "    Classification,\n",
    "    LLMConfiguration,\n",
    "    LLMProvider,\n",
    "    ClassificationLogger,\n",
    "    ClassificationError,\n",
    "    LLMError,\n",
    ")\n",
    "from openness_classifier.config import ClassifierConfig, load_config\n",
    "from openness_classifier.data import (\n",
    "    TrainingExample,\n",
    "    Publication,\n",
    "    EmbeddingModel,\n",
    "    load_training_data,\n",
    "    compute_embeddings,\n",
    ")\n",
    "from openness_classifier.prompts import (\n",
    "    select_knn_examples,\n",
    "    build_few_shot_prompt,\n",
    "    parse_classification_response,\n",
    "    SYSTEM_PROMPT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Class\n",
    "\n",
    "Main classifier that manages training data, embeddings, and LLM calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class OpennessClassifier:\n",
    "    \"\"\"Few-shot LLM classifier for data and code openness.\n",
    "    \n",
    "    Manages training examples, embeddings, and LLM inference.\n",
    "    \n",
    "    Example:\n",
    "        >>> classifier = OpennessClassifier.from_config(load_config())\n",
    "        >>> result = classifier.classify_statement(\n",
    "        ...     \"Data available at https://zenodo.org/record/12345\",\n",
    "        ...     ClassificationType.DATA\n",
    "        ... )\n",
    "        >>> print(result.category)  # OpennessCategory.OPEN\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        config: ClassifierConfig,\n",
    "        data_examples: List[TrainingExample],\n",
    "        code_examples: List[TrainingExample],\n",
    "        embedding_model: EmbeddingModel,\n",
    "        logger: Optional[ClassificationLogger] = None,\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.data_examples = data_examples\n",
    "        self.code_examples = code_examples\n",
    "        self.embedding_model = embedding_model\n",
    "        self.llm_provider = LLMProvider(config.llm)\n",
    "        self.logger = logger\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config: ClassifierConfig) -> 'OpennessClassifier':\n",
    "        \"\"\"Create classifier from configuration.\n",
    "        \n",
    "        Loads training data and computes embeddings.\n",
    "        \"\"\"\n",
    "        # Load training data\n",
    "        data_examples, code_examples = load_training_data(config.training_data_path)\n",
    "        \n",
    "        # Initialize embedding model\n",
    "        embedding_model = EmbeddingModel(config.embedding_model)\n",
    "        \n",
    "        # Compute embeddings\n",
    "        compute_embeddings(data_examples, embedding_model)\n",
    "        compute_embeddings(code_examples, embedding_model)\n",
    "        \n",
    "        # Setup logger\n",
    "        log_path = config.log_dir / f\"classifications_{datetime.now().strftime('%Y%m%d')}.jsonl\"\n",
    "        logger = ClassificationLogger(log_path)\n",
    "        \n",
    "        return cls(\n",
    "            config=config,\n",
    "            data_examples=data_examples,\n",
    "            code_examples=code_examples,\n",
    "            embedding_model=embedding_model,\n",
    "            logger=logger,\n",
    "        )\n",
    "    \n",
    "    def classify_statement(\n",
    "        self,\n",
    "        statement: str,\n",
    "        statement_type: ClassificationType,\n",
    "        return_reasoning: bool = True,\n",
    "        publication_id: Optional[str] = None,\n",
    "    ) -> Classification:\n",
    "        \"\"\"Classify a single availability statement.\n",
    "        \n",
    "        Args:\n",
    "            statement: The availability statement text\n",
    "            statement_type: DATA or CODE\n",
    "            return_reasoning: Include chain-of-thought reasoning\n",
    "            publication_id: Optional ID for logging\n",
    "            \n",
    "        Returns:\n",
    "            Classification result with category, confidence, and reasoning\n",
    "        \"\"\"\n",
    "        # Select appropriate training examples\n",
    "        examples = (self.data_examples if statement_type == ClassificationType.DATA \n",
    "                   else self.code_examples)\n",
    "        \n",
    "        # Select kNN examples\n",
    "        selected = select_knn_examples(\n",
    "            statement=statement,\n",
    "            training_examples=examples,\n",
    "            embedding_model=self.embedding_model,\n",
    "            k=self.config.few_shot_k,\n",
    "        )\n",
    "        \n",
    "        # Build prompt\n",
    "        prompt = build_few_shot_prompt(\n",
    "            statement=statement,\n",
    "            statement_type=statement_type,\n",
    "            examples=selected,\n",
    "            include_reasoning=return_reasoning,\n",
    "        )\n",
    "        \n",
    "        # Prepend system prompt\n",
    "        full_prompt = f\"{SYSTEM_PROMPT}\\n\\n{prompt}\"\n",
    "        \n",
    "        # Call LLM\n",
    "        response = self.llm_provider.complete(full_prompt)\n",
    "        \n",
    "        # Parse response\n",
    "        category, confidence, reasoning = parse_classification_response(response)\n",
    "        \n",
    "        # Create classification result\n",
    "        classification = Classification(\n",
    "            category=category,\n",
    "            statement_type=statement_type,\n",
    "            confidence_score=confidence,\n",
    "            reasoning=reasoning if return_reasoning else None,\n",
    "            model_config=self.config.llm,\n",
    "            few_shot_example_ids=[ex.id for ex in selected],\n",
    "        )\n",
    "        \n",
    "        # Log classification\n",
    "        if self.logger and publication_id:\n",
    "            self.logger.log_classification(\n",
    "                publication_id=publication_id,\n",
    "                classification=classification,\n",
    "                statement_text=statement,\n",
    "            )\n",
    "        \n",
    "        return classification\n",
    "    \n",
    "    def classify_publication(\n",
    "        self,\n",
    "        publication: Publication,\n",
    "        return_reasoning: bool = True,\n",
    "    ) -> Tuple[Optional[Classification], Optional[Classification]]:\n",
    "        \"\"\"Classify both data and code availability for a publication.\n",
    "        \n",
    "        Args:\n",
    "            publication: Publication with data/code statements\n",
    "            return_reasoning: Include reasoning in results\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (data_classification, code_classification)\n",
    "            Either can be None if statement is missing\n",
    "        \"\"\"\n",
    "        data_result = None\n",
    "        code_result = None\n",
    "        \n",
    "        if publication.has_data_statement():\n",
    "            data_result = self.classify_statement(\n",
    "                statement=publication.data_statement,\n",
    "                statement_type=ClassificationType.DATA,\n",
    "                return_reasoning=return_reasoning,\n",
    "                publication_id=publication.id,\n",
    "            )\n",
    "        \n",
    "        if publication.has_code_statement():\n",
    "            code_result = self.classify_statement(\n",
    "                statement=publication.code_statement,\n",
    "                statement_type=ClassificationType.CODE,\n",
    "                return_reasoning=return_reasoning,\n",
    "                publication_id=publication.id,\n",
    "            )\n",
    "        \n",
    "        return data_result, code_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convenience Functions\n",
    "\n",
    "Module-level functions for simpler usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "_default_classifier: Optional[OpennessClassifier] = None\n",
    "\n",
    "\n",
    "def get_classifier(config: Optional[ClassifierConfig] = None) -> OpennessClassifier:\n",
    "    \"\"\"Get or create the default classifier instance.\n",
    "    \n",
    "    Args:\n",
    "        config: Optional configuration (loads from env if not provided)\n",
    "        \n",
    "    Returns:\n",
    "        OpennessClassifier instance\n",
    "    \"\"\"\n",
    "    global _default_classifier\n",
    "    \n",
    "    if _default_classifier is None or config is not None:\n",
    "        if config is None:\n",
    "            config = load_config()\n",
    "        _default_classifier = OpennessClassifier.from_config(config)\n",
    "    \n",
    "    return _default_classifier\n",
    "\n",
    "\n",
    "def classify_statement(\n",
    "    statement: str,\n",
    "    statement_type: ClassificationType | str,\n",
    "    config: Optional[ClassifierConfig] = None,\n",
    "    return_reasoning: bool = True,\n",
    ") -> Classification:\n",
    "    \"\"\"Classify a single availability statement.\n",
    "    \n",
    "    Convenience function that manages classifier lifecycle.\n",
    "    \n",
    "    Args:\n",
    "        statement: The availability statement text\n",
    "        statement_type: \"data\" or \"code\" (or ClassificationType)\n",
    "        config: Optional configuration\n",
    "        return_reasoning: Include reasoning in result\n",
    "        \n",
    "    Returns:\n",
    "        Classification result\n",
    "        \n",
    "    Example:\n",
    "        >>> result = classify_statement(\n",
    "        ...     \"Data available at https://zenodo.org/record/12345\",\n",
    "        ...     \"data\"\n",
    "        ... )\n",
    "        >>> print(result.category.value)  # 'open'\n",
    "    \"\"\"\n",
    "    # Convert string to enum if needed\n",
    "    if isinstance(statement_type, str):\n",
    "        statement_type = ClassificationType(statement_type.lower())\n",
    "    \n",
    "    classifier = get_classifier(config)\n",
    "    return classifier.classify_statement(\n",
    "        statement=statement,\n",
    "        statement_type=statement_type,\n",
    "        return_reasoning=return_reasoning,\n",
    "    )\n",
    "\n",
    "\n",
    "def classify_publication(\n",
    "    data_statement: Optional[str] = None,\n",
    "    code_statement: Optional[str] = None,\n",
    "    publication_id: str = \"unknown\",\n",
    "    config: Optional[ClassifierConfig] = None,\n",
    ") -> Tuple[Optional[Classification], Optional[Classification]]:\n",
    "    \"\"\"Classify data and code availability for a publication.\n",
    "    \n",
    "    Args:\n",
    "        data_statement: Data availability statement (optional)\n",
    "        code_statement: Code availability statement (optional)\n",
    "        publication_id: Identifier for logging\n",
    "        config: Optional configuration\n",
    "        \n",
    "    Returns:\n",
    "        Tuple of (data_classification, code_classification)\n",
    "    \"\"\"\n",
    "    pub = Publication(\n",
    "        id=publication_id,\n",
    "        data_statement=data_statement,\n",
    "        code_statement=code_statement,\n",
    "    )\n",
    "    \n",
    "    classifier = get_classifier(config)\n",
    "    return classifier.classify_publication(pub)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low Confidence Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def identify_low_confidence(\n",
    "    classifications: List[Classification],\n",
    "    threshold: float = 0.5\n",
    ") -> List[Classification]:\n",
    "    \"\"\"Identify classifications with low confidence scores.\n",
    "    \n",
    "    Use this to find statements that may need manual review.\n",
    "    \n",
    "    Args:\n",
    "        classifications: List of classification results\n",
    "        threshold: Confidence threshold (default: 0.5)\n",
    "        \n",
    "    Returns:\n",
    "        List of low-confidence classifications\n",
    "    \"\"\"\n",
    "    return [c for c in classifications if c.confidence_score < threshold]\n",
    "\n",
    "\n",
    "def suggest_training_examples(\n",
    "    classifications: List[Tuple[str, Classification]],\n",
    "    threshold: float = 0.5,\n",
    "    max_suggestions: int = 10\n",
    ") -> List[Tuple[str, Classification]]:\n",
    "    \"\"\"Suggest statements that would benefit from manual coding.\n",
    "    \n",
    "    Returns low-confidence classifications that should be manually\n",
    "    reviewed and potentially added to training data.\n",
    "    \n",
    "    Args:\n",
    "        classifications: List of (statement_text, classification) tuples\n",
    "        threshold: Confidence threshold\n",
    "        max_suggestions: Maximum suggestions to return\n",
    "        \n",
    "    Returns:\n",
    "        List of (statement, classification) tuples needing review\n",
    "    \"\"\"\n",
    "    low_conf = [\n",
    "        (stmt, cls) for stmt, cls in classifications\n",
    "        if cls.confidence_score < threshold\n",
    "    ]\n",
    "    \n",
    "    # Sort by confidence (lowest first)\n",
    "    low_conf.sort(key=lambda x: x[1].confidence_score)\n",
    "    \n",
    "    return low_conf[:max_suggestions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: Full testing requires API keys and is done in examples/01_single_classification.ipynb\n",
    "print(\"Classifier module ready!\")\n",
    "print(\"To test, set up your .env file with API keys and run:\")\n",
    "print(\"  from openness_classifier import classify_statement\")\n",
    "print(\"  result = classify_statement('Data available at Zenodo', 'data')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
