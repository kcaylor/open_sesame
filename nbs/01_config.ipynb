{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration Module\n",
    "\n",
    "> Configuration management for the openness classifier.\n",
    "\n",
    "This module handles:\n",
    "- Loading configuration from environment variables\n",
    "- Saving/loading configuration to/from JSON files\n",
    "- Validating configuration settings\n",
    "\n",
    "Configuration follows the 12-factor app methodology, loading sensitive values (API keys) from environment variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Any\n",
    "from dataclasses import dataclass, field, asdict\n",
    "from datetime import datetime\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openness_classifier.core import (\n",
    "    LLMConfiguration, \n",
    "    LLMProviderType,\n",
    "    ConfigurationError\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ClassifierConfig\n",
    "\n",
    "Main configuration class for the classifier, including LLM settings and paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class ClassifierConfig:\n",
    "    \"\"\"Complete configuration for the openness classifier.\n",
    "    \n",
    "    Attributes:\n",
    "        llm: LLM provider configuration\n",
    "        training_data_path: Path to training data CSV\n",
    "        log_dir: Directory for classification logs\n",
    "        few_shot_k: Number of few-shot examples to use\n",
    "        embedding_model: Sentence transformer model for similarity\n",
    "    \"\"\"\n",
    "    llm: LLMConfiguration\n",
    "    training_data_path: Path = Path('resources/abpoll-open-b71bd12/data/processed/articles_reviewed.csv')\n",
    "    log_dir: Path = Path('logs')\n",
    "    few_shot_k: int = 5\n",
    "    embedding_model: str = 'all-MiniLM-L6-v2'\n",
    "    \n",
    "    def __post_init__(self):\n",
    "        \"\"\"Ensure paths are Path objects.\"\"\"\n",
    "        if isinstance(self.training_data_path, str):\n",
    "            self.training_data_path = Path(self.training_data_path)\n",
    "        if isinstance(self.log_dir, str):\n",
    "            self.log_dir = Path(self.log_dir)\n",
    "    \n",
    "    def to_dict(self) -> Dict[str, Any]:\n",
    "        \"\"\"Convert to dictionary for serialization.\"\"\"\n",
    "        return {\n",
    "            'llm': self.llm.to_dict(),\n",
    "            'training_data_path': str(self.training_data_path),\n",
    "            'log_dir': str(self.log_dir),\n",
    "            'few_shot_k': self.few_shot_k,\n",
    "            'embedding_model': self.embedding_model,\n",
    "        }\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dict(cls, data: Dict[str, Any]) -> 'ClassifierConfig':\n",
    "        \"\"\"Create from dictionary.\"\"\"\n",
    "        return cls(\n",
    "            llm=LLMConfiguration.from_dict(data['llm']),\n",
    "            training_data_path=Path(data.get('training_data_path', \n",
    "                'resources/abpoll-open-b71bd12/data/processed/articles_reviewed.csv')),\n",
    "            log_dir=Path(data.get('log_dir', 'logs')),\n",
    "            few_shot_k=data.get('few_shot_k', 5),\n",
    "            embedding_model=data.get('embedding_model', 'all-MiniLM-L6-v2'),\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Configuration\n",
    "\n",
    "Load configuration from environment variables or JSON files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_config(\n",
    "    config_path: Optional[str | Path] = None,\n",
    "    env_file: Optional[str | Path] = None\n",
    ") -> ClassifierConfig:\n",
    "    \"\"\"Load classifier configuration.\n",
    "    \n",
    "    Priority order:\n",
    "    1. JSON config file (if provided)\n",
    "    2. Environment variables (from .env file or system)\n",
    "    3. Default values\n",
    "    \n",
    "    Args:\n",
    "        config_path: Optional path to JSON config file\n",
    "        env_file: Optional path to .env file (default: .env)\n",
    "        \n",
    "    Returns:\n",
    "        ClassifierConfig with loaded settings\n",
    "        \n",
    "    Raises:\n",
    "        ConfigurationError: If configuration is invalid or missing required values\n",
    "    \"\"\"\n",
    "    # Load .env file if it exists\n",
    "    if env_file:\n",
    "        load_dotenv(env_file)\n",
    "    else:\n",
    "        load_dotenv()  # Load from .env in current directory\n",
    "    \n",
    "    # If JSON config provided, load from it\n",
    "    if config_path:\n",
    "        config_path = Path(config_path)\n",
    "        if config_path.exists():\n",
    "            with open(config_path) as f:\n",
    "                return ClassifierConfig.from_dict(json.load(f))\n",
    "        else:\n",
    "            raise ConfigurationError(f\"Config file not found: {config_path}\")\n",
    "    \n",
    "    # Load from environment variables\n",
    "    return _load_from_env()\n",
    "\n",
    "\n",
    "def _load_from_env() -> ClassifierConfig:\n",
    "    \"\"\"Load configuration from environment variables.\"\"\"\n",
    "    # Get provider\n",
    "    provider_str = os.getenv('LLM_PROVIDER', 'claude').lower()\n",
    "    try:\n",
    "        provider = LLMProviderType(provider_str)\n",
    "    except ValueError:\n",
    "        raise ConfigurationError(\n",
    "            f\"Invalid LLM_PROVIDER: {provider_str}. \"\n",
    "            f\"Must be one of: claude, openai, ollama\"\n",
    "        )\n",
    "    \n",
    "    # Get model name with provider-specific defaults\n",
    "    default_models = {\n",
    "        LLMProviderType.CLAUDE: 'claude-3-5-sonnet-20241022',\n",
    "        LLMProviderType.OPENAI: 'gpt-4-turbo',\n",
    "        LLMProviderType.OLLAMA: 'llama3:8b',\n",
    "    }\n",
    "    model_name = os.getenv('LLM_MODEL_NAME', default_models[provider])\n",
    "    \n",
    "    # Validate API key exists for non-Ollama providers\n",
    "    api_key = None\n",
    "    if provider == LLMProviderType.CLAUDE:\n",
    "        api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "        if not api_key:\n",
    "            raise ConfigurationError(\n",
    "                \"ANTHROPIC_API_KEY not found in environment. \"\n",
    "                \"Set it in your .env file or environment.\"\n",
    "            )\n",
    "    elif provider == LLMProviderType.OPENAI:\n",
    "        api_key = os.getenv('OPENAI_API_KEY')\n",
    "        if not api_key:\n",
    "            raise ConfigurationError(\n",
    "                \"OPENAI_API_KEY not found in environment. \"\n",
    "                \"Set it in your .env file or environment.\"\n",
    "            )\n",
    "    \n",
    "    # Build LLM config\n",
    "    llm_config = LLMConfiguration(\n",
    "        provider=provider,\n",
    "        model_name=model_name,\n",
    "        temperature=float(os.getenv('LLM_TEMPERATURE', '0.1')),\n",
    "        max_tokens=int(os.getenv('LLM_MAX_TOKENS', '500')),\n",
    "        top_p=float(os.getenv('LLM_TOP_P', '0.95')),\n",
    "        api_endpoint=os.getenv('OLLAMA_BASE_URL') if provider == LLMProviderType.OLLAMA else None,\n",
    "        api_key_hash=LLMConfiguration.hash_api_key(api_key) if api_key else None,\n",
    "    )\n",
    "    \n",
    "    # Build full config\n",
    "    return ClassifierConfig(\n",
    "        llm=llm_config,\n",
    "        training_data_path=Path(os.getenv(\n",
    "            'TRAINING_DATA_PATH',\n",
    "            'resources/abpoll-open-b71bd12/data/processed/articles_reviewed.csv'\n",
    "        )),\n",
    "        log_dir=Path(os.getenv('LOG_DIR', 'logs')),\n",
    "        few_shot_k=int(os.getenv('FEW_SHOT_K', '5')),\n",
    "        embedding_model=os.getenv('EMBEDDING_MODEL', 'all-MiniLM-L6-v2'),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def save_config(config: ClassifierConfig, path: str | Path) -> None:\n",
    "    \"\"\"Save configuration to JSON file.\n",
    "    \n",
    "    Note: API keys are NOT saved - only their hashes for audit trail.\n",
    "    \n",
    "    Args:\n",
    "        config: Configuration to save\n",
    "        path: Output path for JSON file\n",
    "    \"\"\"\n",
    "    path = Path(path)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    with open(path, 'w') as f:\n",
    "        json.dump(config.to_dict(), f, indent=2)\n",
    "\n",
    "\n",
    "def create_example_config(path: str | Path = 'example_config.json') -> None:\n",
    "    \"\"\"Create an example configuration file for documentation.\n",
    "    \n",
    "    Args:\n",
    "        path: Output path for example config\n",
    "    \"\"\"\n",
    "    example = ClassifierConfig(\n",
    "        llm=LLMConfiguration(\n",
    "            provider=LLMProviderType.CLAUDE,\n",
    "            model_name='claude-3-5-sonnet-20241022',\n",
    "            temperature=0.1,\n",
    "            max_tokens=500,\n",
    "            top_p=0.95,\n",
    "            api_key_hash='<hash_of_your_api_key>',\n",
    "        ),\n",
    "        training_data_path=Path('resources/abpoll-open-b71bd12/data/processed/articles_reviewed.csv'),\n",
    "        log_dir=Path('logs'),\n",
    "        few_shot_k=5,\n",
    "        embedding_model='all-MiniLM-L6-v2',\n",
    "    )\n",
    "    \n",
    "    save_config(example, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test configuration loading (will fail without API key, which is expected)\n",
    "import os\n",
    "\n",
    "# Test with mock environment\n",
    "os.environ['LLM_PROVIDER'] = 'ollama'  # Ollama doesn't need API key\n",
    "os.environ['LLM_MODEL_NAME'] = 'llama3:8b'\n",
    "os.environ['OLLAMA_BASE_URL'] = 'http://localhost:11434'\n",
    "\n",
    "try:\n",
    "    config = load_config()\n",
    "    print(f\"Provider: {config.llm.provider.value}\")\n",
    "    print(f\"Model: {config.llm.model_name}\")\n",
    "    print(f\"Training data: {config.training_data_path}\")\n",
    "    print(\"Config loading test passed!\")\n",
    "except ConfigurationError as e:\n",
    "    print(f\"Expected error (no API key): {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
